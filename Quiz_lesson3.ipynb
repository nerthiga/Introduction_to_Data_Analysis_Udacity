{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyPksXtpGHDy/OVd1AANmBjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerthiga/Introduction_to_Data_Analysis_Udacity/blob/main/Quiz_lesson3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gckyOtNLQeCM"
      },
      "source": [
        "def mean_riders_for_max_station(ridership):\n",
        "    '''\n",
        "    Fill in this function to find the station with the maximum riders on the\n",
        "    first day, then return the mean riders per day for that station. Also\n",
        "    return the mean ridership overall for comparsion.\n",
        "    \n",
        "    Hint: NumPy's argmax() function might be useful:\n",
        "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
        "    '''\n",
        "    \n",
        "    max_station = ridership[0, :].argmax()\n",
        "    overall_mean = ridership.mean()\n",
        "    mean_for_max = ridership[:, max_station].mean() \n",
        "    \n",
        "    return (overall_mean, mean_for_max)\n",
        "    \n",
        "print mean_riders_for_max_station(ridership)    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP3oHrtRRA0B"
      },
      "source": [
        "ridership = np.array([\n",
        "    [   0,    0,    2,    5,    0],\n",
        "    [1478, 3877, 3674, 2328, 2539],\n",
        "    [1613, 4088, 3991, 6461, 2691],\n",
        "    [1560, 3392, 3826, 4787, 2613],\n",
        "    [1608, 4802, 3932, 4477, 2705],\n",
        "    [1576, 3933, 3909, 4979, 2685],\n",
        "    [  95,  229,  255,  496,  201],\n",
        "    [   2,    0,    1,   27,    0],\n",
        "    [1438, 3785, 3589, 4174, 2215],\n",
        "    [1342, 4043, 4009, 4665, 3033]\n",
        "])\n",
        "\n",
        "def min_and_max_riders_per_day(ridership):\n",
        "    '''\n",
        "    Fill in this function. First, for each subway station, calculate the\n",
        "    mean ridership per day. Then, out of all the subway stations, return the\n",
        "    maximum and minimum of these values. That is, find the maximum\n",
        "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
        "    subway station.\n",
        "    '''\n",
        "    mean_for_each_station = ridership.mean(axis=0)\n",
        "    max_daily_ridership =  mean_for_each_station.max()    # Replace this with your code\n",
        "    min_daily_ridership =  mean_for_each_station.min()   # Replace this with your code\n",
        "    \n",
        "    return (max_daily_ridership, min_daily_ridership)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDRIomvWRSac"
      },
      "source": [
        "def mean_riders_for_max_station(ridership_df):\n",
        "    '''\n",
        "    Fill in this function to find the station with the maximum riders on the\n",
        "    first day, then return the mean riders per day for that station. Also\n",
        "    return the mean ridership overall for comparsion.\n",
        "    \n",
        "    This is the same as a previous exercise, but this time the\n",
        "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
        "    '''\n",
        "    max_station = ridership_df.iloc[0].argmax()\n",
        "    overall_mean = ridership_df.values.mean() # Replace this with your code\n",
        "    mean_for_max = ridership_df[max_station].mean() # Replace this with your code\n",
        "    \n",
        "    return (overall_mean, mean_for_max)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGGGL0n9X9ZJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
        "subway_df = pd.read_csv(filename)\n",
        "\n",
        "def correlation(x, y):\n",
        "    '''\n",
        "    Fill in this function to compute the correlation between the two\n",
        "    input variables. Each input is either a NumPy array or a Pandas\n",
        "    Series.\n",
        "    \n",
        "    correlation = average of (x in standard units) times (y in standard units)\n",
        "    \n",
        "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
        "    '''\n",
        "    std_x = (x-x.mean())/x.std(ddof=0)\n",
        "    std_y = (y-y.mean())/y.std(ddof=0)\n",
        "    \n",
        "    return (std_x*std_y).mean()\n",
        "\n",
        "entries = subway_df['ENTRIESn_hourly']\n",
        "cum_entries = subway_df['ENTRIESn']\n",
        "rain = subway_df['meanprecipi']\n",
        "temp = subway_df['meantempi']\n",
        "\n",
        "print correlation(entries, rain)\n",
        "print correlation(entries, temp)\n",
        "print correlation(rain, temp)\n",
        "\n",
        "print correlation(entries, cum_entries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMK7SZtZYSbc"
      },
      "source": [
        "entries_and_exits = pd.DataFrame({\n",
        "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
        "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
        "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
        "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
        "})\n",
        "\n",
        "def get_hourly_entries_and_exits(entries_and_exits):\n",
        "    '''\n",
        "    Fill in this function to take a DataFrame with cumulative entries\n",
        "    and exits (entries in the first column, exits in the second) and\n",
        "    return a DataFrame with hourly entries and exits (entries in the\n",
        "    first column, exits in the second).\n",
        "    '''\n",
        "    return (entries_and_exits - entries_and_exits.shift(1))\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9AUu8dYf3c"
      },
      "source": [
        "grades_df = pd.DataFrame(\n",
        "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
        "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
        "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
        "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
        ")\n",
        "\n",
        "\n",
        "def convert_grade(grade):\n",
        "    if grade>=90:\n",
        "        return 'A'\n",
        "    elif grade>=80:\n",
        "        return 'B'\n",
        "    elif grade>=70:\n",
        "        return 'C'\n",
        "    elif grade>=60:\n",
        "        return 'D'\n",
        "    else:\n",
        "        return 'F'\n",
        "    \n",
        "def convert_grades(grades_df):\n",
        "    '''\n",
        "    Fill in this function to convert the given DataFrame of numerical\n",
        "    grades to letter grades. Return a new DataFrame with the converted\n",
        "    grade.\n",
        "    \n",
        "    The conversion rule is:\n",
        "        90-100 -> A\n",
        "        80-89  -> B\n",
        "        70-79  -> C\n",
        "        60-69  -> D\n",
        "        0-59   -> F\n",
        "    '''\n",
        "    return grades_df.applymap(convert_grade)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4POJhQPiy8ww"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "grades_df = pd.DataFrame(\n",
        "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
        "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
        "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
        "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
        ")\n",
        "\n",
        "# Change False to True for this block of code to see what it does\n",
        "\n",
        "# DataFrame apply()\n",
        "if True:\n",
        "    def convert_grades_curve(exam_grades):\n",
        "        # Pandas has a bult-in function that will perform this calculation\n",
        "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
        "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
        "        # the qcut() function here:\n",
        "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
        "        return pd.qcut(exam_grades,\n",
        "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
        "                       labels=['F', 'D', 'C', 'B', 'A'])\n",
        "        \n",
        "    # qcut() operates on a list, array, or Series. This is the\n",
        "    # result of running the function on a single column of the\n",
        "    # DataFrame.\n",
        "    print convert_grades_curve(grades_df['exam1'])\n",
        "    \n",
        "    # qcut() does not work on DataFrames, but we can use apply()\n",
        "    # to call the function on each column separately\n",
        "    print grades_df.apply(convert_grades_curve)\n",
        "    \n",
        "def standardize_column(column):\n",
        "    return (column-column.mean())/column.std(ddof=0)\n",
        "    \n",
        "def standardize(df):\n",
        "    '''\n",
        "    Fill in this function to standardize each column of the given\n",
        "    DataFrame. To standardize a variable, convert each value to the\n",
        "    number of standard deviations it is above or below the mean.\n",
        "    '''\n",
        "    return df.apply(standardize_column)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN9usbwkzR5M"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'a': [4, 5, 3, 1, 2],\n",
        "    'b': [20, 10, 40, 50, 30],\n",
        "    'c': [25, 20, 5, 15, 10]\n",
        "})\n",
        "\n",
        "# Change False to True for this block of code to see what it does\n",
        "\n",
        "# DataFrame apply() - use case 2\n",
        "if True:   \n",
        "    print df.apply(np.mean)\n",
        "    print df.apply(np.max)\n",
        "    \n",
        "def second_largest_in_column(df):\n",
        "    sorted_column = df.sort_values(ascending=False)\n",
        "    return sorted_column.iloc[1]\n",
        "    \n",
        "    \n",
        "def second_largest(df):\n",
        "    '''\n",
        "    Fill in this function to return the second-largest value of each \n",
        "    column of the input DataFrame.\n",
        "    '''\n",
        "    return df.apply(second_largest_in_column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTnRRdXs0tKL"
      },
      "source": [
        "grades_df = pd.DataFrame(\n",
        "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
        "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
        "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
        "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
        ")\n",
        "\n",
        "def standardize(grades_df):\n",
        "    '''\n",
        "    Fill in this function to standardize each column of the given\n",
        "    DataFrame. To standardize a variable, convert each value to the\n",
        "    number of standard deviations it is above or below the mean.\n",
        "    \n",
        "    This time, try to use vectorized operations instead of apply().\n",
        "    You should get the same results as you did before.\n",
        "    '''\n",
        "    return (grades_df-grades_df.mean())/grades_df.std(ddof=0)\n",
        "\n",
        "def standardize_rows(grades_df):\n",
        "    '''\n",
        "    Optional: Fill in this function to standardize each row of the given\n",
        "    DataFrame. Again, try not to use apply().\n",
        "    \n",
        "    This one is more challenging than standardizing each column!\n",
        "    '''\n",
        "    \n",
        "    mean_diff = grades_df.sub(grades_df.mean(axis='columns'),axis = 'index')\n",
        "    \n",
        "    return mean_diff.div(grades_df.std(axis='columns',ddof=0), axis='index')\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kECvkrTL-R4T"
      },
      "source": [
        "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
        "subway_df = pd.read_csv(filename)\n",
        "\n",
        "### Write code here to group the subway data by a variable of your choice, then\n",
        "### either print out the mean ridership within each group or create a plot.\n",
        "\n",
        "grouped_data = subway_df.groupby('rain')\n",
        "print grouped_data.mean()['ENTRIESn_hourly']\n",
        "\n",
        "days = subway_df.groupby('day_week')\n",
        "print days.mean()['ENTRIESn_hourly']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z66Bd9UfxleO"
      },
      "source": [
        "# DataFrame with cumulative entries and exits for multiple stations\n",
        "ridership_df = pd.DataFrame({\n",
        "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
        "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
        "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
        "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
        "})\n",
        "\n",
        "def entries_and_exits(entry_and_exit):\n",
        "    return (entry_and_exit - entry_and_exit.shift())\n",
        "\n",
        "def get_hourly_entries_and_exits(entries_and_exits):\n",
        "    '''\n",
        "    Fill in this function to take a DataFrame with cumulative entries\n",
        "    and exits and return a DataFrame with hourly entries and exits.\n",
        "    The hourly entries and exits should be calculated separately for\n",
        "    each station (the 'UNIT' column).\n",
        "    \n",
        "    Hint: Take a look at the `get_hourly_entries_and_exits()` function\n",
        "    you wrote in a previous quiz, DataFrame Vectorized Operations. If\n",
        "    you copy it here and rename it, you can use it and the `.apply()`\n",
        "    function to help solve this problem.\n",
        "    '''\n",
        "    return (entries_and_exits - entries_and_exits.shift(1))\n",
        "grouped_data = ridership_df.groupby('UNIT')[['ENTRIESn', 'EXITSn']]\n",
        "print grouped_data.apply(get_hourly_entries_and_exits)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}